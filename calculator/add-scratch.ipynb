{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = ['0','1','2','3','4','5','6','7','8','9','$','+','='] # All the chars needed for addition\n",
    "vocab_size = len(chars)\n",
    "# tokenize chars\n",
    "stoi = {x:i for i,x in enumerate(chars)}\n",
    "itos = {i:x for i,x in enumerate(chars)}\n",
    "encode = lambda s: [stoi[c] for c in s]\n",
    "decode = lambda xs: \"\".join([itos[x] for x in xs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "# hyperparameters\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "dropout=0.2\n",
    "# -----------------\n",
    "\n",
    "# ---------------- MODELS\n",
    "class MultiHeadAttention(nn.Module):\n",
    "\n",
    "    def __init__(self, n_head, head_size, block_size, n_embed):\n",
    "        super().__init__()\n",
    "        self.proj = nn.Linear(n_embed, n_embed)\n",
    "        self.key = nn.Linear(n_embed, n_embed, bias=False)\n",
    "        self.query = nn.Linear(n_embed, n_embed, bias=False)\n",
    "        self.value = nn.Linear(n_embed, n_embed, bias=False)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
    "        self.head_size = head_size\n",
    "        self.n_head = n_head\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, C = x.shape\n",
    "        k = self.key(x)\n",
    "        q = self.query(x)\n",
    "        v = self.value(x)\n",
    "\n",
    "        k = k.view(B, T,self.n_head, C//self.n_head).transpose(1, 2)\n",
    "        q = q.view(B, T,self.n_head, C//self.n_head).transpose(1, 2)\n",
    "        v = v.view(B, T, self.n_head, C//self.n_head).transpose(1, 2)\n",
    "        # q @ k.T => (B, n_head,T, head_size) @ (B, n_head, T, head_size) => (B, n_head, T, T)\n",
    "        wei = (q@ k.transpose(-2, -1))\n",
    "        wei *= self.head_size**-0.5\n",
    "        wei = wei.masked_fill(self.tril[:T,:T] ==0, float('-inf'))\n",
    "        wei = F.softmax(wei, dim=-1)\n",
    "        out = wei @ v\n",
    "        out = out.transpose(1,2).contiguous().view(B, T, C)\n",
    "        out = self.drop(self.proj(out))\n",
    "        return out\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "\n",
    "    def __init__(self, n_embed):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_embed, 4*n_embed),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4*n_embed, n_embed),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "    \n",
    "class Block(nn.Module):\n",
    "    def __init__(self, n_embed, n_head, block_size):\n",
    "        super().__init__()\n",
    "        head_size = n_embed // n_head\n",
    "        self.sa = MultiHeadAttention(n_head, head_size, block_size ,n_embed=n_embed)\n",
    "        self.ln1 = nn.LayerNorm(n_embed) # Normalize the last dim (C) which is n_embed\n",
    "        self.ffwd = FeedForward(n_embed)\n",
    "        self.ln2 = nn.LayerNorm(n_embed)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.sa(self.ln1(x))+ x\n",
    "        x = self.ffwd(self.ln2(x)) + x\n",
    "        return x\n",
    "    \n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, vocab_size, block_size, n_embed, n_head, n_layer):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embed)\n",
    "        self.position_embedding_table = nn.Embedding(block_size, n_embed)\n",
    "        self.blocks = nn.Sequential(*[Block(n_embed, n_head, block_size) for _ in range(n_layer)])\n",
    "        self.lm_head = nn.Linear(n_embed, vocab_size)\n",
    "        self.block_size = block_size\n",
    "        \n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        B, T = idx.shape\n",
    "\n",
    "        token_emb = self.token_embedding_table(idx)  # B, T, C  (C is n_embed)\n",
    "        position_emb = self.position_embedding_table(torch.arange(T, device=device)) # T, C (create an embedding for each time step)\n",
    "        x = token_emb + position_emb # (B, T, C)\n",
    "        x = self.blocks(x)\n",
    "        logits = self.lm_head(x) # B, T, vocab_size\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else: \n",
    "            # Need to reshape for cross_entropy\n",
    "            B,T,C = logits.shape\n",
    "            logits = logits.view(B*T,C) # 32 65\n",
    "            targets = targets.view(B*T) # 32\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        return logits, loss        \n",
    "\n",
    "    def generate(self, idx, max_tokens):\n",
    "        \n",
    "        # idx is (B, T) array of current context\n",
    "        for _ in range(max_tokens):\n",
    "            # get the predictions\n",
    "            logits, loss= self(idx[:,-self.block_size:])\n",
    "            # Focus on the last time dimension\n",
    "            logits = logits[:,-1,:]\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "            idx = torch.cat((idx, idx_next), dim=1)\n",
    "        return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201869\n"
     ]
    }
   ],
   "source": [
    "model = torch.load('./models/model_add2_2024-07-23-22-05.pth')\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(total_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9+19=\n",
      "108\n"
     ]
    }
   ],
   "source": [
    "problem = '9+19='\n",
    "context = torch.tensor(encode(problem), dtype=torch.long).view(1,-1)\n",
    "print(problem)\n",
    "print(decode(model.generate(idx=context, max_tokens=3)[0][len(context[0]):].tolist()[::-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(context[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10, 6, 1]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.generate(idx=context, max_tokens=3)[0][len(context[0]):].tolist()[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "data = torch.randint(10,(1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[7, 3, 2] has 3 numbers. 7 + 3 = 01. 10 + 2 = 21. 7 + 3 + 2 = 21$'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def getChainOfThoughtData(data):\n",
    "    return\"\".join([f'[{a}, {b}, {c}] has 3 numbers. {a} + {b} = {str(a+b)[::-1]}. {a+b} + {c} = {str(a+b+c)[::-1]}. {a} + {b} + {c} = {str(a+b+c)[::-1]}$' for [a, b, c] in data.tolist()])\n",
    "\n",
    "getChainOfThoughtData(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([15,  7, 17, 14,  9, 17, 14,  3, 16, 14, 18, 19, 27, 14,  3, 14, 21, 22,\n",
       "        23, 24, 25, 26, 27, 13, 14,  7, 14, 11, 14,  9, 14, 12, 14,  1,  6, 13,\n",
       "        14,  7, 14, 11, 14,  9, 14, 12, 14,  1,  6, 13, 14,  1,  6, 14, 11, 14,\n",
       "         3, 14, 12, 14,  1,  9, 13, 14,  7, 14, 11, 14,  9, 14, 11, 14,  3, 14,\n",
       "        12, 14,  1,  9, 10])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getRandomData(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "# hyperparameters\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "dropout=0.2\n",
    "# -----------------\n",
    "\n",
    "# ---------------- MODELS\n",
    "class MultiHeadAttention(nn.Module):\n",
    "\n",
    "    def __init__(self, n_head, head_size, block_size, n_embed):\n",
    "        super().__init__()\n",
    "        self.proj = nn.Linear(n_embed, n_embed)\n",
    "        self.key = nn.Linear(n_embed, n_embed, bias=False)\n",
    "        self.query = nn.Linear(n_embed, n_embed, bias=False)\n",
    "        self.value = nn.Linear(n_embed, n_embed, bias=False)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
    "        self.head_size = head_size\n",
    "        self.n_head = n_head\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, C = x.shape\n",
    "        k = self.key(x)\n",
    "        q = self.query(x)\n",
    "        v = self.value(x)\n",
    "\n",
    "        k = k.view(B, T,self.n_head, C//self.n_head).transpose(1, 2)\n",
    "        q = q.view(B, T,self.n_head, C//self.n_head).transpose(1, 2)\n",
    "        v = v.view(B, T, self.n_head, C//self.n_head).transpose(1, 2)\n",
    "        # q @ k.T => (B, n_head,T, head_size) @ (B, n_head, T, head_size) => (B, n_head, T, T)\n",
    "        wei = (q@ k.transpose(-2, -1))\n",
    "        wei *= self.head_size**-0.5\n",
    "        wei = wei.masked_fill(self.tril[:T,:T] ==0, float('-inf'))\n",
    "        wei = F.softmax(wei, dim=-1)\n",
    "        out = wei @ v\n",
    "        out = out.transpose(1,2).contiguous().view(B, T, C)\n",
    "        out = self.drop(self.proj(out))\n",
    "        return out\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "\n",
    "    def __init__(self, n_embed):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_embed, 4*n_embed),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4*n_embed, n_embed),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "    \n",
    "class Block(nn.Module):\n",
    "    def __init__(self, n_embed, n_head, block_size):\n",
    "        super().__init__()\n",
    "        head_size = n_embed // n_head\n",
    "        self.sa = MultiHeadAttention(n_head, head_size, block_size ,n_embed=n_embed)\n",
    "        self.ln1 = nn.LayerNorm(n_embed) # Normalize the last dim (C) which is n_embed\n",
    "        self.ffwd = FeedForward(n_embed)\n",
    "        self.ln2 = nn.LayerNorm(n_embed)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.sa(self.ln1(x))+ x\n",
    "        x = self.ffwd(self.ln2(x)) + x\n",
    "        return x\n",
    "    \n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, vocab_size, block_size, n_embed, n_head, n_layer):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embed)\n",
    "        self.position_embedding_table = nn.Embedding(block_size, n_embed)\n",
    "        self.blocks = nn.Sequential(*[Block(n_embed, n_head, block_size) for _ in range(n_layer)])\n",
    "        self.lm_head = nn.Linear(n_embed, vocab_size)\n",
    "        self.block_size = block_size\n",
    "        \n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        B, T = idx.shape\n",
    "\n",
    "        token_emb = self.token_embedding_table(idx)  # B, T, C  (C is n_embed)\n",
    "        position_emb = self.position_embedding_table(torch.arange(T, device=device)) # T, C (create an embedding for each time step)\n",
    "        x = token_emb + position_emb # (B, T, C)\n",
    "        x = self.blocks(x)\n",
    "        logits = self.lm_head(x) # B, T, vocab_size\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else: \n",
    "            # Need to reshape for cross_entropy\n",
    "            B,T,C = logits.shape\n",
    "            logits = logits.view(B*T,C) # 32 65\n",
    "            targets = targets.view(B*T) # 32\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        return logits, loss        \n",
    "\n",
    "    def generate(self, idx, max_tokens):\n",
    "        \n",
    "        # idx is (B, T) array of current context\n",
    "        for _ in range(max_tokens):\n",
    "            # get the predictions\n",
    "            logits, loss= self(idx[:,-self.block_size:])\n",
    "            # Focus on the last time dimension\n",
    "            logits = logits[:,-1,:]\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "            if(idx_next.item() == 10):\n",
    "                break\n",
    "            idx = torch.cat((idx, idx_next), dim=1)\n",
    "        return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "model = torch.load('./models/model_add2_2024-07-28-08-45.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getAccuracy(max_int=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1+3+9= 51'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode(model.generate(idx=torch.tensor(encode('1+3+9='), dtype=torch.long).view(1,-1), max_tokens=20)[0].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1, 11,  3, 11,  2, 12, 14,  4,  1, 13, 14,  4, 14, 11, 14,  9]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.generate(idx=torch.tensor(encode('1+3+2='), dtype=torch.long).view(1,-1), max_tokens=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
